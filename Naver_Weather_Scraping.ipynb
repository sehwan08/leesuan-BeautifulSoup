{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482d995a",
   "metadata": {},
   "source": [
    "### 네이버 날씨 스크래핑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a7b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd8ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "def scrape_weather():\n",
    "    print(\"[오늘의 날씨]\")\n",
    "    url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%84%9C%EC%9A%B8+%EB%82%A0%EC%94%A8\"\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    # 맑음, 어제보다 00 높아요\n",
    "    weather = soup.find('span', class_=\"weather before_slash\").get_text()\n",
    "    cast = soup.find(\"p\", attrs={'class':'summary'}).get_text().replace(\"맑음\",\"\")\n",
    "    \n",
    "    # 현재 00도 (최저 00 / 최고 00)\n",
    "    curr_temp = soup.find('div', class_='temperature_text').get_text().strip()\n",
    "    curr_temp = curr_temp.replace(\"현재 온도\", \"현재 온도: \")\n",
    "    min_temp = soup.find('span', class_='lowest').get_text().replace(\"최저기온\",\"최저 기온: \")\n",
    "    max_temp = soup.find('span',class_='highest').get_text().replace(\"최고기온\",\"최고 기온: \")\n",
    "    \n",
    "    # 강수 확률\n",
    "    moring_rain_rate = soup.select_one('div > div.list_box > ul > li:nth-child(1) > div > div.cell_weather > span:nth-child(1) > span').get_text().strip()\n",
    "    afternoon_rain_rate = soup.select_one('div > div.list_box > ul > li:nth-child(1) > div > div.cell_weather > span:nth-child(2) > span').get_text().strip()\n",
    "    \n",
    "    # 미세 먼지\n",
    "    #똑같은 태그에 여러 클래스가 존재하면 리스트 형식으로 받으면 된다. \n",
    "    #클래스, 아이디, 속성 등으로 여러개 찾고 싶을때는 {'class':'', 'id':''} 식으로 찾음\n",
    "    #특정 태그의 특성을 완벽히 찾고 싶으면 {'class':''}, text='' 이런식으로 구분자를 주면 됨\n",
    "    dust = soup.find('ul', class_='today_chart_list')\n",
    "    pm10 = dust.find_all('li')[0].get_text().strip().replace(\"미세먼지\", \"미세먼지: \")\n",
    "    pm25 = dust.find_all('li')[1].get_text().strip().replace(\"초미세먼지\", \"초미세먼지: \")\n",
    "    print(weather + \", \"+cast)\n",
    "    print(curr_temp)\n",
    "    print(min_temp)\n",
    "    print(max_temp)\n",
    "    print(\"강수 확률: \" + moring_rain_rate)\n",
    "    print(\"강수 확률: \" + afternoon_rain_rate)\n",
    "    print(pm10)\n",
    "    print(pm25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e722d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[오늘의 날씨]\n",
      "맑음, 어제보다 0° 높아요   \n",
      "현재 온도: 0°\n",
      "최저 기온: -6°\n",
      "최고 기온: 4°\n",
      "강수 확률: 오전 0%\n",
      "강수 확률: 오후 0%\n",
      "자외선 좋음\n",
      "일몰 17:29\n"
     ]
    }
   ],
   "source": [
    "scrape_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53e098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74bcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401da07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e310f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
