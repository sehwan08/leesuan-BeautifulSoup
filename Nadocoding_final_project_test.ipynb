{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f614502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c11e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(url):\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "def print_news(index, title, link):\n",
    "    print(\"{}. {}\".format(index+1, title))\n",
    "    print(\"링크 : {}\".format(link))\n",
    "    \n",
    "def scrape_english():\n",
    "    print(\"[오늘의 영어 회화]\")\n",
    "    print()\n",
    "    url = \"https://www.hackers.co.kr/?c=s_eng/eng_contents/I_others_english\"\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    sentences = soup.find_all('div', attrs={'id':re.compile('^conv_kor_t')})\n",
    "    \n",
    "#     print(len(sentences)//2)\n",
    "    \n",
    "    print('- 영어 지문 -')\n",
    "    for sentence in sentences[len(sentences)//2:]: # 8문장이라고 가정, 4~7이 영어, 0~3이 한글\n",
    "        print(sentence.get_text().strip())\n",
    "        \n",
    "    print()\n",
    "    print('- 한글 지문 -')\n",
    "    for sentence in sentences[:len(sentences)//2]:\n",
    "        print(sentence.get_text().strip())\n",
    "    print()\n",
    "\n",
    "def scrape_headline_news():\n",
    "    print(\"[최신 뉴스]\")\n",
    "    url = \"https://news.naver.com/\"\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    news = soup.find('div', class_='cjs_channel_card')\n",
    "    news_list = news.find_all('div', class_='cjs_journal_wrap _item_contents', limit=3)\n",
    "    \n",
    "    for index, news in enumerate(news_list):\n",
    "        title = news.find('div', class_='cjs_t').get_text().strip()\n",
    "        link = news.find('a', class_='cjs_news_a').get('href')\n",
    "        \n",
    "        print_news(index, title, link)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    \n",
    "def scrape_it_news():\n",
    "    print(\"[IT 뉴스]\")\n",
    "    url = \"https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=105&sid2=230\"\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    news_list = soup.find('ul', class_='type06_headline').find_all('li', limit=3)\n",
    "    for index, news in enumerate(news_list):\n",
    "        a = news.select('ul.type06_headline > li > dl > dt.photo > a > img')\n",
    "        title = a[0].attrs['alt']\n",
    "        link = news.find('a').get('href')\n",
    "        print_news(index, title, link)\n",
    "    \n",
    "    print()\n",
    "\n",
    "def scrape_weather():\n",
    "    print(\"[오늘의 날씨]\")\n",
    "    url = \"https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%84%9C%EC%9A%B8+%EB%82%A0%EC%94%A8\"\n",
    "    soup = create_soup(url)\n",
    "    \n",
    "    # 맑음, 어제보다 00 높아요\n",
    "    weather = soup.find('span', class_=\"weather before_slash\").get_text()\n",
    "    cast = soup.find(\"p\", attrs={'class':'summary'}).get_text().replace(\"맑음\",\"\")\n",
    "    \n",
    "    # 현재 00도 (최저 00 / 최고 00)\n",
    "    curr_temp = soup.find('div', class_='temperature_text').get_text().strip()\n",
    "    curr_temp = curr_temp.replace(\"현재 온도\", \"현재 온도: \")\n",
    "    min_temp = soup.find('span', class_='lowest').get_text().replace(\"최저기온\",\"최저 기온: \")\n",
    "    max_temp = soup.find('span',class_='highest').get_text().replace(\"최고기온\",\"최고 기온: \")\n",
    "    \n",
    "    # 강수 확률\n",
    "    moring_rain_rate = soup.select_one('div > div.list_box > ul > li:nth-child(1) > div > div.cell_weather > span:nth-child(1) > span').get_text().strip()\n",
    "    afternoon_rain_rate = soup.select_one('div > div.list_box > ul > li:nth-child(1) > div > div.cell_weather > span:nth-child(2) > span').get_text().strip()\n",
    "    \n",
    "    # 미세 먼지\n",
    "    #똑같은 태그에 여러 클래스가 존재하면 리스트 형식으로 받으면 된다. \n",
    "    #클래스, 아이디, 속성 등으로 여러개 찾고 싶을때는 {'class':'', 'id':''} 식으로 찾음\n",
    "    #특정 태그의 특성을 완벽히 찾고 싶으면 {'class':''}, text='' 이런식으로 구분자를 주면 됨\n",
    "    dust = soup.find('ul', class_='today_chart_list')\n",
    "    pm10 = dust.find_all('li')[0].get_text().strip().replace(\"미세먼지\", \"미세먼지: \")\n",
    "    pm25 = dust.find_all('li')[1].get_text().strip().replace(\"초미세먼지\", \"초미세먼지: \")\n",
    "    print(weather + \", \"+cast)\n",
    "    print(curr_temp)\n",
    "    print(min_temp)\n",
    "    print(max_temp)\n",
    "    print(\"강수 확률: \" + moring_rain_rate)\n",
    "    print(\"강수 확률: \" + afternoon_rain_rate)\n",
    "    print(pm10)\n",
    "    print(pm25)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2ea1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[오늘의 날씨]\n",
      "맑음, 어제보다 0° 높아요   \n",
      "현재 온도: -1°\n",
      "최저 기온: -6°\n",
      "최고 기온: 4°\n",
      "강수 확률: 오전 0%\n",
      "강수 확률: 오후 0%\n",
      "미세먼지:  보통\n",
      "초미세먼지:  나쁨\n",
      "\n",
      "[최신 뉴스]\n",
      "1. 비트코인 5100만원대로↓ 이더리움 400만원대 붕괴…계속되는 코인 하락세\n",
      "링크 : https://n.news.naver.com/article/243/0000021102\n",
      "2. 차선 안 비켜줬다고 인도까지 넘어가며 급제동·보복운전…차주는 \"깜빡이 켰잖아\" (영상)\n",
      "링크 : https://n.news.naver.com/article/119/0002565012\n",
      "3. 보디빌더 대회 4등 女…\"前남편 조롱에 자극 받아, 現애인 15살 연하 \"\n",
      "링크 : https://n.news.naver.com/article/003/0010933201\n",
      "\n",
      "\n",
      "[IT 뉴스]\n",
      "1. “면보다 스프 먼저 넣는게 더 맛있다?” 라면맛 과학적 근거가\n",
      "링크 : https://news.naver.com/main/read.naver?mode=LS2D&mid=shm&sid1=105&sid2=230&oid=016&aid=0001934790\n",
      "2. 카카오 차기대표 ‘먹튀 논란’에 직원 1800여명 “류영준 반대”\n",
      "링크 : https://news.naver.com/main/read.naver?mode=LS2D&mid=shm&sid1=105&sid2=230&oid=293&aid=0000037580\n",
      "3. 국내 규제 막혀 해외로…'뉴코애드윈드', DH 손잡고 한국 뜬다\n",
      "링크 : https://news.naver.com/main/read.naver?mode=LS2D&mid=shm&sid1=105&sid2=230&oid=293&aid=0000037579\n",
      "\n",
      "\n",
      "[오늘의 영어 회화]\n",
      "\n",
      "- 영어 지문 -\n",
      "Mr. Kim: We need to know how long it will take you to deliver the products.\n",
      "Sarah: I cannot give you an exact answer at this time, but it will probably not take more than two months.\n",
      "Mr. Kim: All right, that will be acceptable.\n",
      "Sarah: I will send you a fax with an exact time frame.\n",
      "\n",
      "- 한글 지문 -\n",
      "Mr. Kim: 제품이 배달되는데 얼마나 걸릴지를 알아야 합니다.\n",
      "Sarah: 지금은 분명한 대답을 줄 수 없어요. 하지만 아마도 두 달 이상 걸리지는 않을 거에요.\n",
      "Mr. Kim: 좋아요, 그 정도면 괜찮습니다.\n",
      "Sarah: 정확한 시간 계획에 대해서는 팩스로 보내드릴게요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scrape_weather()\n",
    "    print()\n",
    "    scrape_headline_news()\n",
    "    print()\n",
    "    scrape_it_news()\n",
    "    print()\n",
    "    scrape_english()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0537f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3102e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d497c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a747d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71852bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
